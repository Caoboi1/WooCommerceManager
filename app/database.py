# Corrected the duplicate update_category method and removed the potentially problematic site_name column reference.
"""
Database Manager - Qu·∫£n l√Ω c∆° s·ªü d·ªØ li·ªáu SQLite

COMPONENT OVERVIEW:
------------------
SQLite database manager cho ·ª©ng d·ª•ng WooCommerce Product Manager.
Qu·∫£n l√Ω 2 b·∫£ng ch√≠nh: sites v√† products v·ªõi foreign key relationships.

DATABASE SCHEMA:
---------------
sites table:
- id (PRIMARY KEY): Unique identifier
- name: T√™n hi·ªÉn th·ªã c·ªßa site
- url: URL c·ªßa WooCommerce site
- consumer_key: WooCommerce REST API consumer key
- consumer_secret: WooCommerce REST API consumer secret
- is_active: Boolean flag cho tr·∫°ng th√°i ho·∫°t ƒë·ªông
- notes: Ghi ch√∫ v·ªÅ site
- created_at, updated_at: Timestamps

products table:
- id (PRIMARY KEY): Unique identifier
- site_id (FOREIGN KEY): Li√™n k·∫øt v·ªõi sites.id
- wc_product_id: ID s·∫£n ph·∫©m tr√™n WooCommerce
- name, sku, price, regular_price, sale_price: Th√¥ng tin s·∫£n ph·∫©m
- stock_quantity: S·ªë l∆∞·ª£ng kho
- status: Tr·∫°ng th√°i s·∫£n ph·∫©m (publish, draft, private)
- description, short_description: M√¥ t·∫£ s·∫£n ph·∫©m
- categories, tags: Ph√¢n lo·∫°i (comma-separated strings)
- images: URLs h√¨nh ·∫£nh (comma-separated)
- last_sync: Timestamp ƒë·ªìng b·ªô cu·ªëi c√πng
- created_at, updated_at: Timestamps

INDEXES:
--------
- idx_products_site_id: Index tr√™n site_id cho performance
- idx_products_sku: Index tr√™n SKU cho t√¨m ki·∫øm
- idx_products_wc_id: Index tr√™n wc_product_id

OPERATIONS:
-----------
Sites: create, get, get_all, get_active, update, delete
Products: create, get, get_all, get_by_site, update, delete, search
Statistics: get_products_stats

ERROR HANDLING:
--------------
- T·∫•t c·∫£ operations ƒë·ªÅu c√≥ try/catch v·ªõi logging
- Connection management v·ªõi context managers
- Foreign key constraints ƒë∆∞·ª£c enforce
"""

import sqlite3
import logging
from typing import List, Optional, Dict, Any
from datetime import datetime
import os

from app.models import Site, Product

class DatabaseManager:
    """Qu·∫£n l√Ω c∆° s·ªü d·ªØ li·ªáu SQLite"""

    def __init__(self, db_path: str = "woocommerce_manager.db"):
        self.db_path = db_path
        # Initialize logger with safe configuration
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)

        # Prevent recursion by limiting handlers
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))
            self.logger.addHandler(handler)

        self.logger.propagate = False

    def get_connection(self) -> sqlite3.Connection:
        """L·∫•y k·∫øt n·ªëi database v·ªõi timeout v√† retry"""
        import time
        max_retries = 3
        retry_delay = 0.1
        
        for attempt in range(max_retries):
            try:
                conn = sqlite3.connect(self.db_path, timeout=30.0)  # 30 second timeout
                conn.row_factory = sqlite3.Row
                # Enable WAL mode for better concurrency
                conn.execute("PRAGMA journal_mode=WAL")
                conn.execute("PRAGMA synchronous=NORMAL")
                conn.execute("PRAGMA cache_size=10000")
                conn.execute("PRAGMA temp_store=MEMORY")
                return conn
            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and attempt < max_retries - 1:
                    time.sleep(retry_delay * (attempt + 1))
                    continue
                else:
                    raise e

    def init_database(self):
        """Kh·ªüi t·∫°o database v√† c√°c b·∫£ng"""
        try:
            # T·∫°o th∆∞ m·ª•c ch·ª©a database n·∫øu ch∆∞a c√≥
            db_dir = os.path.dirname(self.db_path)
            if db_dir and not os.path.exists(db_dir):
                os.makedirs(db_dir, exist_ok=True)
            
            # Ki·ªÉm tra quy·ªÅn ghi file
            try:
                test_conn = sqlite3.connect(self.db_path)
                test_conn.close()
            except Exception as e:
                self.logger.error(f"Cannot create database file: {e}")
                # Th·ª≠ t·∫°o trong th∆∞ m·ª•c temp
                import tempfile
                self.db_path = os.path.join(tempfile.gettempdir(), "woocommerce_manager.db")
                self.logger.info(f"Using temporary database: {self.db_path}")
            
            with self.get_connection() as conn:
                # T·∫°o b·∫£ng sites
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS sites (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        name TEXT NOT NULL,
                        url TEXT NOT NULL,
                        consumer_key TEXT NOT NULL,
                        consumer_secret TEXT NOT NULL,
                        wp_username TEXT,
                        wp_app_password TEXT,
                        is_active BOOLEAN DEFAULT 1,
                        notes TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # T·∫°o b·∫£ng products
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS products (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        site_id INTEGER NOT NULL,
                        wc_product_id INTEGER,
                        name TEXT,
                        sku TEXT,
                        price REAL,
                        regular_price REAL,
                        sale_price REAL,
                        stock_quantity INTEGER,
                        status TEXT,
                        description TEXT,
                        short_description TEXT,
                        categories TEXT,
                        tags TEXT,
                        images TEXT,
                        view_count INTEGER DEFAULT 0,
                        order_count INTEGER DEFAULT 0,
                        last_sync TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (site_id) REFERENCES sites (id) ON DELETE CASCADE
                    )
                """)

                # Create categories table
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS categories (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        site_id INTEGER NOT NULL,
                        wc_category_id INTEGER,
                        name TEXT NOT NULL,
                        slug TEXT,
                        parent_id INTEGER,
                        description TEXT,
                        count INTEGER,
                        image TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (site_id) REFERENCES sites (id) ON DELETE CASCADE
                    )
                """)

                # Create pages table
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS pages (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        site_id INTEGER NOT NULL,
                        wp_page_id INTEGER,
                        title TEXT,
                        content TEXT,
                        excerpt TEXT,
                        status TEXT,
                        slug TEXT,
                        parent_id INTEGER,
                        menu_order INTEGER,
                        featured_media INTEGER,
                        author INTEGER,
                        last_sync TIMESTAMP,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (site_id) REFERENCES sites (id) ON DELETE CASCADE
                    )
                """)

                # Create folder_scans table
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS folder_scans (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        original_title TEXT NOT NULL,
                        path TEXT NOT NULL UNIQUE,
                        image_count INTEGER DEFAULT 0,
                        description TEXT,
                        status TEXT DEFAULT 'pending',
                        new_title TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # Create saved_scans table for managing scan results
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS saved_scans (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        name TEXT NOT NULL UNIQUE,
                        description TEXT,
                        folder_count INTEGER DEFAULT 0,
                        data TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # Th√™m c·ªôt m·ªõi n·∫øu ch∆∞a c√≥
                try:
                    conn.execute("ALTER TABLE folder_scans ADD COLUMN data_name TEXT")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                try:
                    conn.execute("ALTER TABLE folder_scans ADD COLUMN category_id INTEGER")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                try:
                    conn.execute("ALTER TABLE folder_scans ADD COLUMN site_id INTEGER")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                # Th√™m c·ªôt wc_product_id v√†o b·∫£ng folder_scans n·∫øu ch∆∞a c√≥
                try:
                    conn.execute("ALTER TABLE folder_scans ADD COLUMN wc_product_id INTEGER")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                # Th√™m c√°c c·ªôt upload status
                try:
                    conn.execute("ALTER TABLE folder_scans ADD COLUMN uploaded_at TEXT")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                try:
                    conn.execute("ALTER TABLE folder_scans ADD COLUMN upload_success BOOLEAN DEFAULT 0")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                try:
                    conn.execute("ALTER TABLE folder_scans ADD COLUMN error_message TEXT")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                try:
                    conn.execute("ALTER TABLE folder_scans ADD COLUMN product_url TEXT")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                # T·∫°o indexes (sau khi ƒë√£ th√™m c·ªôt)
                conn.execute("CREATE INDEX IF NOT EXISTS idx_products_site_id ON products (site_id)")
                conn.execute("CREATE INDEX IF NOT EXISTS idx_products_sku ON products (sku)")
                conn.execute("CREATE INDEX IF NOT EXISTS idx_products_wc_id ON products (wc_product_id)")
                conn.execute("CREATE INDEX IF NOT EXISTS idx_folder_scans_path ON folder_scans (path)")
                conn.execute("CREATE INDEX IF NOT EXISTS idx_folder_scans_status ON folder_scans (status)")

                # Ki·ªÉm tra xem c·ªôt data_name c√≥ t·ªìn t·∫°i tr∆∞·ªõc khi t·∫°o index
                try:
                    conn.execute("CREATE INDEX IF NOT EXISTS idx_folder_scans_data_name ON folder_scans (data_name)")
                except Exception:
                    pass  # C·ªôt ch∆∞a t·ªìn t·∫°i ho·∫∑c index ƒë√£ c√≥

                try:
                    conn.execute("CREATE INDEX IF NOT EXISTS idx_folder_scans_category ON folder_scans (category_id)")
                except Exception:
                    pass  # C·ªôt ch∆∞a t·ªìn t·∫°i ho·∫∑c index ƒë√£ c√≥

                try:
                    conn.execute("CREATE INDEX IF NOT EXISTS idx_folder_scans_site ON folder_scans (site_id)")
                except Exception:
                    pass  # C·ªôt ch∆∞a t·ªìn t·∫°i ho·∫∑c index ƒë√£ c√≥

                # Th√™m c·ªôt wp_username v√† wp_app_password n·∫øu ch∆∞a c√≥
                try:
                    conn.execute("ALTER TABLE sites ADD COLUMN wp_username TEXT")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                try:
                    conn.execute("ALTER TABLE sites ADD COLUMN wp_app_password TEXT")
                except Exception:
                    pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

                # C·∫≠p nh·∫≠t indexes cho hi·ªáu su·∫•t
                try:
                    conn.execute("CREATE INDEX IF NOT EXISTS idx_sites_active ON sites(is_active)")
                    conn.execute("CREATE INDEX IF NOT EXISTS idx_products_site ON products(site_id)")
                    conn.execute("CREATE INDEX IF NOT EXISTS idx_categories_site ON categories(site_id)")
                except Exception:
                    pass

                conn.commit()
                self.logger.info("Database initialized successfully")

        except Exception as e:
            self.logger.error(f"Database initialization failed: {str(e)}")
            # Th·ª≠ t·∫°o database ƒë∆°n gi·∫£n h∆°n
            try:
                self.create_minimal_database()
                self.logger.info("Created minimal database successfully")
            except Exception as fallback_error:
                self.logger.error(f"Fallback database creation failed: {fallback_error}")
                raise e

    def create_minimal_database(self):
        """T·∫°o database t·ªëi thi·ªÉu v·ªõi c√°c b·∫£ng c∆° b·∫£n"""
        with self.get_connection() as conn:
            # Ch·ªâ t·∫°o b·∫£ng sites c∆° b·∫£n
            conn.execute("""
                CREATE TABLE IF NOT EXISTS sites (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL,
                    url TEXT NOT NULL,
                    consumer_key TEXT NOT NULL,
                    consumer_secret TEXT NOT NULL,
                    is_active BOOLEAN DEFAULT 1,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Ch·ªâ t·∫°o b·∫£ng products c∆° b·∫£n
            conn.execute("""
                CREATE TABLE IF NOT EXISTS products (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    site_id INTEGER NOT NULL,
                    name TEXT,
                    status TEXT DEFAULT 'draft',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (site_id) REFERENCES sites (id)
                )
            """)
            
            conn.commit()

    # Site operations
    def create_site(self, site_data: Dict[str, Any]) -> int:
        """T·∫°o site m·ªõi"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    INSERT INTO sites (name, url, consumer_key, consumer_secret, wp_username, wp_app_password, is_active, notes)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    site_data['name'],
                    site_data['url'],
                    site_data['consumer_key'],
                    site_data['consumer_secret'],
                    site_data.get('wp_username', ''),
                    site_data.get('wp_app_password', ''),
                    site_data.get('is_active', True),
                    site_data.get('notes', '')
                ))
                conn.commit()
                return cursor.lastrowid

        except Exception as e:
            self.logger.error(f"Error creating site: {str(e)}")
            raise

    def get_site(self, site_id: int) -> Optional[Site]:
        """L·∫•y th√¥ng tin site theo ID"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("SELECT * FROM sites WHERE id = ?", (site_id,))
                row = cursor.fetchone()
                if row:
                    return Site.from_dict(dict(row))
                return None

        except Exception as e:
            self.logger.error(f"Error getting site {site_id}: {str(e)}")
            return None

    def get_site_by_id(self, site_id: int) -> Optional[Site]:
        """Alias cho get_site ƒë·ªÉ t∆∞∆°ng th√≠ch"""
        return self.get_site(site_id)

    def get_all_sites(self) -> List[Site]:
        """L·∫•y t·∫•t c·∫£ sites"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("SELECT * FROM sites ORDER BY name")
                rows = cursor.fetchall()
                return [Site.from_dict(dict(row)) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting all sites: {str(e)}")
            return []

    def get_active_sites(self) -> List[Site]:
        """L·∫•y c√°c sites ƒëang ho·∫°t ƒë·ªông"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("SELECT * FROM sites WHERE is_active = 1 ORDER BY name")
                rows = cursor.fetchall()
                return [Site.from_dict(dict(row)) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting active sites: {str(e)}")
            return []

    def update_site(self, site_id: int, site_data: Dict[str, Any]):
        """C·∫≠p nh·∫≠t th√¥ng tin site"""
        try:
            with self.get_connection() as conn:
                conn.execute("""
                    UPDATE sites 
                    SET name = ?, url = ?, consumer_key = ?, consumer_secret = ?, 
                        wp_username = ?, wp_app_password = ?, is_active = ?, notes = ?, 
                        updated_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                """, (
                    site_data['name'],
                    site_data['url'],
                    site_data['consumer_key'],
                    site_data['consumer_secret'],
                    site_data.get('wp_username', ''),
                    site_data.get('wp_app_password', ''),
                    site_data.get('is_active', True),
                    site_data.get('notes', ''),
                    site_id
                ))
                conn.commit()

        except Exception as e:
            self.logger.error(f"Error updating site {site_id}: {str(e)}")
            raise

    def delete_site(self, site_id: int):
        """X√≥a site"""
        try:
            with self.get_connection() as conn:
                # X√≥a t·∫•t c·∫£ s·∫£n ph·∫©m c·ªßa site tr∆∞·ªõc
                conn.execute("DELETE FROM products WHERE site_id = ?", (site_id,))
                # X√≥a site
                conn.execute("DELETE FROM sites WHERE id = ?", (site_id,))
                conn.commit()

        except Exception as e:
            self.logger.error(f"Error deleting site {site_id}: {str(e)}")
            raise

    # Product operations
    def create_product(self, product_data: Dict[str, Any]) -> int:
        """T·∫°o s·∫£n ph·∫©m m·ªõi"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    INSERT INTO products (
                        site_id, wc_product_id, name, sku, price, regular_price, sale_price,
                        stock_quantity, status, description, short_description,
                        categories, tags, images, last_sync
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    product_data['site_id'],
                    product_data.get('wc_product_id'),
                    product_data.get('name'),
                    product_data.get('sku'),
                    product_data.get('price'),
                    product_data.get('regular_price'),
                    product_data.get('sale_price'),
                    product_data.get('stock_quantity'),
                    product_data.get('status'),
                    product_data.get('description'),
                    product_data.get('short_description'),
                    product_data.get('categories'),
                    product_data.get('tags'),
                    product_data.get('images'),
                    product_data.get('last_sync')
                ))
                conn.commit()
                return cursor.lastrowid

        except Exception as e:
            self.logger.error(f"Error creating product: {str(e)}")
            raise

    def get_product(self, product_id: int) -> Optional[Product]:
        """L·∫•y th√¥ng tin s·∫£n ph·∫©m theo ID"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("SELECT * FROM products WHERE id = ?", (product_id,))
                row = cursor.fetchone()
                if row:
                    return Product.from_dict(dict(row))
                return None

        except Exception as e:
            self.logger.error(f"Error getting product {product_id}: {str(e)}")
            return None

    def get_product_by_site_and_wc_id(self, site_id: int, wc_product_id: int) -> Optional[Product]:
        """L·∫•y s·∫£n ph·∫©m theo site_id v√† wc_product_id"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute(
                    "SELECT * FROM products WHERE site_id = ? AND wc_product_id = ?", 
                    (site_id, wc_product_id)
                )
                row = cursor.fetchone()
                if row:
                    return Product.from_dict(dict(row))
                return None

        except Exception as e:
            self.logger.error(f"Error getting product by site and wc id: {str(e)}")
            return None

    def get_all_products(self) -> List[Product]:
        """L·∫•y t·∫•t c·∫£ s·∫£n ph·∫©m"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("SELECT * FROM products ORDER BY name")
                rows = cursor.fetchall()
                return [Product.from_dict(dict(row)) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting all products: {str(e)}")
            return []

    def get_products_by_site(self, site_id: int) -> List[Product]:
        """L·∫•y s·∫£n ph·∫©m theo site"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute(
                    "SELECT * FROM products WHERE site_id = ? ORDER BY name", 
                    (site_id,)
                )
                rows = cursor.fetchall()
                return [Product.from_dict(dict(row)) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting products by site {site_id}: {str(e)}")
            return []

    def update_product(self, product_id: int, product_data: Dict[str, Any]):
        """C·∫≠p nh·∫≠t th√¥ng tin s·∫£n ph·∫©m v·ªõi retry logic"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                with self.get_connection() as conn:
                    conn.execute("BEGIN IMMEDIATE")
                    conn.execute("""
                        UPDATE products 
                        SET site_id = ?, wc_product_id = ?, name = ?, sku = ?, 
                            price = ?, regular_price = ?, sale_price = ?,
                            stock_quantity = ?, status = ?, description = ?, 
                            short_description = ?, categories = ?, tags = ?, 
                            images = ?, last_sync = ?, updated_at = CURRENT_TIMESTAMP
                        WHERE id = ?
                    """, (
                        product_data['site_id'],
                        product_data.get('wc_product_id'),
                        product_data.get('name'),
                        product_data.get('sku'),
                        product_data.get('price'),
                        product_data.get('regular_price'),
                        product_data.get('sale_price'),
                        product_data.get('stock_quantity'),
                        product_data.get('status'),
                        product_data.get('description'),
                        product_data.get('short_description'),
                        product_data.get('categories'),
                        product_data.get('tags'),
                        product_data.get('images'),
                        product_data.get('last_sync'),
                        product_id
                    ))
                    conn.commit()
                    return  # Success, exit function

            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and attempt < max_retries - 1:
                    import time
                    time.sleep(0.1 * (attempt + 1))
                    continue
                else:
                    self.logger.error(f"Error updating product {product_id}: {str(e)}")
                    raise
            except Exception as e:
                self.logger.error(f"Error updating product {product_id}: {str(e)}")
                raise

    def delete_product(self, product_id: int) -> bool:
        """X√≥a s·∫£n ph·∫©m"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("DELETE FROM products WHERE id = ?", (product_id,))
                conn.commit()
                return cursor.rowcount > 0

        except Exception as e:
            self.logger.error(f"Error deleting product {product_id}: {str(e)}")
            return False

    def search_products(self, search_term: str) -> List[Product]:
        """T√¨m ki·∫øm s·∫£n ph·∫©m"""
        try:
            with self.get_connection() as conn:
                search_pattern = f"%{search_term}%"
                cursor = conn.execute("""
                    SELECT * FROM products 
                    WHERE name LIKE ? OR sku LIKE ? OR description LIKE ?
                    ORDER BY name
                """, (search_pattern, search_pattern, search_pattern))
                rows = cursor.fetchall()
                return [Product.from_dict(dict(row)) for row in rows]

        except Exception as e:
            self.logger.error(f"Error searching products: {str(e)}")
            return []

    def get_products_stats(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ s·∫£n ph·∫©m"""
        try:
            with self.get_connection() as conn:
                # T·ªïng s·ªë s·∫£n ph·∫©m
                cursor = conn.execute("SELECT COUNT(*) as total FROM products")
                total = cursor.fetchone()['total']

                # S·∫£n ph·∫©m theo tr·∫°ng th√°i
                cursor = conn.execute("""
                    SELECT status, COUNT(*) as count 
                    FROM products 
                    GROUP BY status
                """)
                status_stats = {row['status']: row['count'] for row in cursor.fetchall()}

                # S·∫£n ph·∫©m theo site
                cursor = conn.execute("""
                    SELECT s.name, COUNT(p.id) as count
                    FROM sites s
                    LEFT JOIN products p ON s.id = p.site_id
                    GROUP BY s.id, s.name
                """)
                site_stats = {row['name']: row['count'] for row in cursor.fetchall()}

                return {
                    'total_products': total,
                    'by_status': status_stats,
                    'by_site': site_stats
                }

        except Exception as e:
            self.logger.error(f"Error getting product stats: {str(e)}")
            return {}

    # Category operations
    def create_category(self, category_data: Dict[str, Any]) -> int:
        """T·∫°o category m·ªõi"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    INSERT INTO categories (
                        site_id, wc_category_id, name, slug, parent_id,
                        description, count, image
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    category_data['site_id'],
                    category_data.get('wc_category_id'),
                    category_data['name'],
                    category_data.get('slug', ''),
                    category_data.get('parent_id', 0),
                    category_data.get('description', ''),
                    category_data.get('count', 0),
                    category_data.get('image', '')
                ))
                conn.commit()
                return cursor.lastrowid

        except Exception as e:
            self.logger.error(f"Error creating category: {str(e)}")
            raise

    def get_category_by_id(self, category_id: int) -> Optional[Dict[str, Any]]:
        """L·∫•y category theo ID"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT c.*, s.name as site_name 
                    FROM categories c
                    LEFT JOIN sites s ON c.site_id = s.id
                    WHERE c.id = ?
                """, (category_id,))
                row = cursor.fetchone()
                return dict(row) if row else None
        except Exception as e:
            self.logger.error(f"Error getting category by id {category_id}: {str(e)}")
            return None

    def get_all_categories(self) -> List[Dict[str, Any]]:
        """L·∫•y t·∫•t c·∫£ categories"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT c.*, s.name as site_name 
                    FROM categories c
                    LEFT JOIN sites s ON c.site_id = s.id
                    ORDER BY c.name
                """)
                return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            self.logger.error(f"Error getting all categories: {str(e)}")
            return []

    def get_categories_by_site(self, site_id: int) -> List[Dict[str, Any]]:
        """L·∫•y categories theo site"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT c.*, s.name as site_name 
                    FROM categories c
                    LEFT JOIN sites s ON c.site_id = s.id
                    WHERE c.site_id = ?
                    ORDER BY 
                        CASE WHEN c.parent_id IS NULL OR c.parent_id = 0 THEN 0 ELSE 1 END,
                        c.name
                """, (site_id,))
                rows = cursor.fetchall()
                categories = [dict(row) for row in rows]

                self.logger.debug(f"Found {len(categories)} categories for site {site_id}")
                return categories

        except Exception as e:
            self.logger.error(f"Error getting categories by site {site_id}: {str(e)}")
            return []

    def update_category(self, category_id: int, category_data: Dict[str, Any]):
        """C·∫≠p nh·∫≠t category"""
        try:
            with self.get_connection() as conn:
                # T·∫°o c√¢u UPDATE ƒë·ªông t·ª´ category_data, b·ªè qua c√°c c·ªôt kh√¥ng t·ªìn t·∫°i
                set_clauses = []
                values = []

                # Danh s√°ch c√°c c·ªôt h·ª£p l·ªá trong b·∫£ng categories
                valid_columns = {
                    'site_id', 'wc_category_id', 'name', 'slug', 'parent_id', 
                    'description', 'count', 'image'
                }

                for key, value in category_data.items():
                    if key != 'id' and key in valid_columns:  # Ch·ªâ update c√°c c·ªôt h·ª£p l·ªá
                        set_clauses.append(f"{key} = ?")
                        values.append(value)

                if set_clauses:
                    set_clauses.append("updated_at = CURRENT_TIMESTAMP")
                    values.append(category_id)

                    query = f"UPDATE categories SET {', '.join(set_clauses)} WHERE id = ?"
                    conn.execute(query, values)
                    conn.commit()

        except Exception as e:
            self.logger.error(f"Error updating category {category_id}: {str(e)}")
            raise

    def get_category_by_id(self, category_id: int) -> Optional[Dict[str, Any]]:
        """L·∫•y category theo ID"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT id, site_id, wc_category_id, name, slug, parent_id, 
                           description, count, image, created_at, updated_at
                    FROM categories WHERE id = ?
                """, (category_id,))

                row = cursor.fetchone()
                if row:
                    return {
                        'id': row[0],
                        'site_id': row[1],
                        'wc_category_id': row[2],
                        'name': row[3],
                        'slug': row[4],
                        'parent_id': row[5],
                        'description': row[6],
                        'count': row[7],
                        'image': row[8],
                        'created_at': row[9],
                        'updated_at': row[10]
                    }
                return None

        except Exception as e:
            self.logger.error(f"Error getting category {category_id}: {str(e)}")
            return None

    def delete_category(self, category_id: int):
        """X√≥a category"""
        try:
            with self.get_connection() as conn:
                conn.execute("DELETE FROM categories WHERE id = ?", (category_id,))
                conn.commit()

        except Exception as e:
            self.logger.error(f"Error deleting category {category_id}: {str(e)}")
            raise



    def update_saved_scan(self, scan_id: int, scan_data: Dict[str, Any]) -> bool:
        """C·∫≠p nh·∫≠t saved scan"""
        try:
            with self.get_connection() as conn:
                # T·∫°o c√¢u UPDATE ƒë·ªông t·ª´ scan_data
                set_clauses = []
                values = []
                
                valid_columns = {'name', 'description', 'folder_count', 'data', 'updated_at'}
                
                for key, value in scan_data.items():
                    if key in valid_columns:
                        set_clauses.append(f"{key} = ?")
                        values.append(value)
                
                if set_clauses:
                    values.append(scan_id)
                    query = f"UPDATE saved_scans SET {', '.join(set_clauses)} WHERE id = ?"
                    
                    cursor = conn.execute(query, values)
                    conn.commit()
                    
                    if cursor.rowcount > 0:
                        self.logger.info(f"Updated saved scan {scan_id}")
                        return True
                    else:
                        self.logger.warning(f"No saved scan found with id {scan_id}")
                        return False
                else:
                    self.logger.warning(f"No valid columns to update for saved scan {scan_id}")
                    return False
                    
        except Exception as e:
            self.logger.error(f"Error updating saved scan {scan_id}: {str(e)}")
            return False


    def remove_duplicate_categories(self):
        """X√≥a c√°c categories b·ªã duplicate"""
        try:
            with self.get_connection() as conn:
                # X√≥a categories tr√πng l·∫∑p, gi·ªØ l·∫°i record c√≥ id nh·ªè nh·∫•t
                conn.execute("""
                    DELETE FROM categories 
                    WHERE id NOT IN (
                        SELECT MIN(id) 
                        FROM categories 
                        GROUP BY site_id, wc_category_id, name
                    )
                """)

                deleted_count = conn.total_changes
                conn.commit()

                self.logger.info(f"Removed {deleted_count} duplicate categories")
                return deleted_count

        except Exception as e:
            self.logger.error(f"Error removing duplicate categories: {str(e)}")
            raise

    def save_categories_from_api(self, site_id: int, categories_data: List[Dict]):
        """L∆∞u categories t·ª´ API v√†o database"""
        try:
            with self.get_connection() as conn:
                # X√≥a categories c≈© c·ªßa site n√†y tr∆∞·ªõc
                conn.execute("DELETE FROM categories WHERE site_id = ?", (site_id,))

                # Th√™m categories m·ªõi v·ªõi INSERT OR IGNORE ƒë·ªÉ tr√°nh duplicate
                for category in categories_data:
                    wc_category_id = category.get('id')

                    # Ki·ªÉm tra xem category ƒë√£ t·ªìn t·∫°i ch∆∞a
                    existing = conn.execute("""
                        SELECT id FROM categories 
                        WHERE site_id = ? AND wc_category_id = ?
                    """, (site_id, wc_category_id)).fetchone()

                    if not existing:
                        conn.execute("""
                            INSERT INTO categories (
                                site_id, wc_category_id, name, slug, parent_id,
                                description, count, image, updated_at
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                        """, (
                            site_id,
                            wc_category_id,
                            category.get('name', ''),
                            category.get('slug', ''),
                            category.get('parent', 0),
                            category.get('description', ''),
                            category.get('count', 0),
                            category.get('image', {}).get('src', '') if category.get('image') else ''
                        ))
                    else:
                        # C·∫≠p nh·∫≠t n·∫øu ƒë√£ t·ªìn t·∫°i
                        conn.execute("""
                            UPDATE categories SET
                                name = ?, slug = ?, parent_id = ?, description = ?,
                                count = ?, image = ?, updated_at = CURRENT_TIMESTAMP
                            WHERE site_id = ? AND wc_category_id = ?
                        """, (
                            category.get('name', ''),
                            category.get('slug', ''),
                            category.get('parent', 0),
                            category.get('description', ''),
                            category.get('count', 0),
                            category.get('image', {}).get('src', '') if category.get('image') else '',
                            site_id,
                            wc_category_id
                        ))

                conn.commit()
                self.logger.info(f"Saved {len(categories_data)} categories for site {site_id}")

        except Exception as e:
            self.logger.error(f"Error saving categories from API: {str(e)}")
            raise

    def fix_category_mapping_for_folder_scan(self, folder_id: int, correct_category_name: str) -> bool:
        """Fix category mapping cho folder scan d·ª±a v√†o t√™n category"""
        try:
            with self.get_connection() as conn:
                # L·∫•y th√¥ng tin folder scan
                folder_scan = self.get_folder_scan_by_id(folder_id)
                if not folder_scan:
                    return False

                site_id = folder_scan.get('site_id')
                if not site_id:
                    return False

                # T√¨m category v·ªõi t√™n ƒë√∫ng trong site
                cursor = conn.execute("""
                    SELECT id, wc_category_id FROM categories 
                    WHERE site_id = ? AND name = ?
                """, (site_id, correct_category_name))

                correct_category = cursor.fetchone()
                if not correct_category:
                    self.logger.warning(f"Kh√¥ng t√¨m th·∫•y category '{correct_category_name}' trong site {site_id}")
                    return False

                # C·∫≠p nh·∫≠t folder scan v·ªõi category ID ƒë√∫ng
                conn.execute("""
                    UPDATE folder_scans 
                    SET category_id = ?, updated_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                """, (correct_category['id'], folder_id))

                conn.commit()
                self.logger.info(f"Fixed category mapping for folder {folder_id} to '{correct_category_name}'")
                return True

        except Exception as e:
            self.logger.error(f"Error fixing category mapping: {str(e)}")
            return False

    # Page operations
    def get_all_pages(self) -> List[Dict[str, Any]]:
        """L·∫•y t·∫•t c·∫£ pages"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT p.*, s.name as site_name 
                    FROM pages p 
                    LEFT JOIN sites s ON p.site_id = s.id 
                    ORDER BY p.updated_at DESC
                """)
                rows = cursor.fetchall()
                return [dict(row) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting all pages: {str(e)}")
            return []

    def get_pages_by_site(self, site_id: int) -> List[Dict[str, Any]]:
        """L·∫•y pages theo site"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT p.*, s.name as site_name 
                    FROM pages p 
                    LEFT JOIN sites s ON p.site_id = s.id 
                    WHERE p.site_id = ?
                    ORDER BY p.updated_at DESC
                """, (site_id,))
                rows = cursor.fetchall()
                return [dict(row) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting pages by site {site_id}: {str(e)}")
            return []

    def create_page(self, page_data: Dict[str, Any]) -> int:
        """T·∫°o page m·ªõi"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    INSERT INTO pages (
                        site_id, wp_page_id, title, slug, content, excerpt, status,
                        parent_id, menu_order, featured_media, author, last_sync
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    page_data['site_id'],
                    page_data.get('wp_page_id'),
                    page_data.get('title', ''),
                    page_data.get('slug', ''),
                    page_data.get('content', ''),
                    page_data.get('excerpt', ''),
                    page_data.get('status', 'draft'),
                    page_data.get('parent_id', 0),
                    page_data.get('menu_order', 0),
                    page_data.get('featured_media', 0),
                    page_data.get('author', 0),
                    datetime.now().isoformat()
                ))
                conn.commit()
                return cursor.lastrowid

        except Exception as e:
            self.logger.error(f"Error creating page: {str(e)}")
            raise

    def update_page(self, page_id: int, page_data: Dict[str, Any]) -> bool:
        """C·∫≠p nh·∫≠t page"""
        try:
            with self.get_connection() as conn:
                conn.execute("""
                    UPDATE pages 
                    SET title = ?, slug = ?, content = ?, excerpt = ?, status = ?,
                        parent_id = ?, menu_order = ?, featured_media = ?, author = ?,
                        updated_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                """, (
                    page_data.get('title', ''),
                    page_data.get('slug', ''),
                    page_data.get('content', ''),
                    page_data.get('excerpt', ''),
                    page_data.get('status', 'draft'),
                    page_data.get('parent_id', 0),
                    page_data.get('menu_order', 0),
                    page_data.get('featured_media', 0),
                    page_data.get('author', 0),
                    page_id
                ))
                conn.commit()
                return True

        except Exception as e:
            self.logger.error(f"Error updating page {page_id}: {str(e)}")
            return False

    def delete_page(self, page_id: int) -> bool:
        """X√≥a page"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("DELETE FROM pages WHERE id = ?", (page_id,))
                conn.commit()
                return cursor.rowcount > 0

        except Exception as e:
            self.logger.error(f"Error deleting page {page_id}: {str(e)}")
            return False

    # Folder scan operations
    def get_all_folder_scans(self) -> List[Dict[str, Any]]:
        """L·∫•y t·∫•t c·∫£ folder scans v·ªõi th√¥ng tin site v√† category"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT 
                        fs.*,
                        s.name as site_name,
                        c.name as category_name
                    FROM folder_scans fs
                    LEFT JOIN sites s ON fs.site_id = s.id
                    LEFT JOIN categories c ON fs.category_id = c.id
                    ORDER BY fs.created_at DESC
                """)

                columns = [description[0] for description in cursor.description]
                rows = cursor.fetchall()
                return [dict(zip(columns, row)) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting all folder scans: {str(e)}")
            return []

    def get_folder_scan_by_id(self, folder_id: int) -> Optional[Dict[str, Any]]:
        """L·∫•y folder scan theo ID"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("SELECT * FROM folder_scans WHERE id = ?", (folder_id,))
                row = cursor.fetchone()
                return dict(row) if row else None

        except Exception as e:
            self.logger.error(f"Error getting folder scan {folder_id}: {str(e)}")
            return None

    def update_folder_scan(self, folder_id: int, update_data: Dict[str, Any]) -> bool:
        """C·∫≠p nh·∫≠t folder scan v·ªõi improved error handling v√† transaction isolation"""
        try:
            if not folder_id or not update_data:
                self.logger.warning(f"Invalid input: folder_id={folder_id}, update_data={bool(update_data)}")
                return False

            # Use separate connection for this update to avoid conflicts
            max_retries = 3
            retry_delay = 0.1
            
            for attempt in range(max_retries):
                try:
                    conn = self.get_connection()
                    
                    # Begin immediate transaction to lock the row
                    conn.execute("BEGIN IMMEDIATE")
                    
                    # Ki·ªÉm tra folder c√≥ t·ªìn t·∫°i kh√¥ng
                    check_cursor = conn.execute("SELECT id, status FROM folder_scans WHERE id = ?", (folder_id,))
                    existing_folder = check_cursor.fetchone()
                    
                    if not existing_folder:
                        self.logger.error(f"Folder scan {folder_id} not found in database")
                        conn.rollback()
                        conn.close()
                        return False
                    
                    current_status = existing_folder[1] if existing_folder else None
                    self.logger.info(f"üîç Folder {folder_id} current status: {current_status}")

                    # L·∫•y danh s√°ch c·ªôt c√≥ s·∫µn trong b·∫£ng folder_scans  
                    cursor = conn.execute("PRAGMA table_info(folder_scans)")
                    available_columns = {row[1] for row in cursor.fetchall()}

                    # T·∫°o c√¢u UPDATE ƒë·ªông t·ª´ update_data, ch·ªâ v·ªõi c√°c c·ªôt t·ªìn t·∫°i
                    set_clauses = []
                    values = []
                    skipped_columns = []

                    for key, value in update_data.items():
                        if key != 'id':
                            if key in available_columns:
                                set_clauses.append(f"{key} = ?")
                                values.append(value)
                            else:
                                skipped_columns.append(key)

                    if skipped_columns:
                        self.logger.debug(f"Skipped non-existent columns for folder {folder_id}: {skipped_columns}")

                    if set_clauses:
                        set_clauses.append("updated_at = CURRENT_TIMESTAMP")
                        values.append(folder_id)

                        query = f"UPDATE folder_scans SET {', '.join(set_clauses)} WHERE id = ?"
                        self.logger.info(f"üîÑ Executing update query for folder {folder_id}: {query[:100]}...")
                        self.logger.info(f"üìù Update values: {values}")
                        
                        cursor = conn.execute(query, values)
                        rows_affected = cursor.rowcount
                        
                        # Verify the update before committing
                        verify_cursor = conn.execute("SELECT status, wc_product_id FROM folder_scans WHERE id = ?", (folder_id,))
                        verify_result = verify_cursor.fetchone()
                        
                        if verify_result:
                            new_status = verify_result[0]
                            new_product_id = verify_result[1]
                            self.logger.info(f"üîç Folder {folder_id} new status: {new_status}, product_id: {new_product_id}")
                        
                        if rows_affected > 0:
                            conn.commit()
                            conn.close()
                            self.logger.info(f"‚úÖ Successfully updated {rows_affected} row(s) for folder {folder_id}")
                            return True
                        else:
                            conn.rollback()
                            conn.close()
                            self.logger.warning(f"‚ö†Ô∏è No rows affected when updating folder {folder_id}")
                            return False
                    else:
                        conn.rollback()
                        conn.close()
                        self.logger.warning(f"‚ö†Ô∏è No valid columns to update for folder {folder_id}")
                        return False

                except Exception as e:
                    try:
                        conn.rollback()
                        conn.close()
                    except:
                        pass
                        
                    if "database is locked" in str(e) and attempt < max_retries - 1:
                        import time
                        time.sleep(retry_delay * (attempt + 1))
                        self.logger.warning(f"‚ö†Ô∏è Database locked, retrying attempt {attempt + 2}/{max_retries} for folder {folder_id}")
                        continue
                    else:
                        self.logger.error(f"‚ùå Error updating folder scan {folder_id} on attempt {attempt + 1}: {str(e)}")
                        if attempt == max_retries - 1:
                            import traceback
                            self.logger.error(f"‚ùå Final attempt failed. Traceback: {traceback.format_exc()}")
                        continue
            
            return False

        except Exception as e:
            self.logger.error(f"‚ùå Critical error updating folder scan {folder_id}: {str(e)}")
            import traceback
            self.logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return False

    def bulk_update_folder_scans(self, folder_ids: List[int], update_data: Dict[str, Any]) -> int:
        """C·∫≠p nh·∫≠t h√†ng lo·∫°t folder scans"""
        try:
            updated_count = 0
            with self.get_connection() as conn:
                # T·∫°o c√¢u UPDATE ƒë·ªông t·ª´ update_data
                set_clauses = []
                values = []

                for key, value in update_data.items():
                    if key != 'id':  # Kh√¥ng update id
                        set_clauses.append(f"{key} = ?")
                        values.append(value)

                if set_clauses:
                    set_clauses.append("updated_at = CURRENT_TIMESTAMP")

                    # T·∫°o placeholders cho folder_ids
                    placeholders = ', '.join(['?'] * len(folder_ids))
                    query = f"UPDATE folder_scans SET {', '.join(set_clauses)} WHERE id IN ({placeholders})"

                    # K·∫øt h·ª£p values v·ªõi folder_ids
                    all_values = values + folder_ids

                    cursor = conn.execute(query, all_values)
                    updated_count = cursor.rowcount
                    conn.commit()

            self.logger.info(f"Bulk updated {updated_count} folder scans")
            return updated_count

        except Exception as e:
            self.logger.error(f"Error bulk updating folder scans: {str(e)}")
            return 0

    def create_saved_scan(self, scan_data: Dict[str, Any]) -> int:
        """T·∫°o saved scan m·ªõi"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    INSERT INTO saved_scans (name, description, folder_count, data)
                    VALUES (?, ?, ?, ?)
                """, (
                    scan_data['name'],
                    scan_data.get('description', ''),
                    scan_data.get('folder_count', 0),
                    scan_data.get('data', '')
                ))
                conn.commit()
                return cursor.lastrowid

        except Exception as e:
            self.logger.error(f"Error creating saved scan: {str(e)}")
            raise

    def get_all_saved_scans(self) -> List[Dict[str, Any]]:
        """L·∫•y t·∫•t c·∫£ saved scans"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT * FROM saved_scans 
                    ORDER BY created_at DESC
                """)
                rows = cursor.fetchall()
                return [dict(row) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting all saved scans: {str(e)}")
            return []

    def get_saved_scan_by_id(self, scan_id: int) -> Optional[Dict[str, Any]]:
        """L·∫•y saved scan theo ID"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("SELECT * FROM saved_scans WHERE id = ?", (scan_id,))
                row = cursor.fetchone()
                return dict(row) if row else None

        except Exception as e:
            self.logger.error(f"Error getting saved scan {scan_id}: {str(e)}")
            return None

    def delete_saved_scan(self, scan_id: int):
        """X√≥a saved scan"""
        try:
            with self.get_connection() as conn:
                conn.execute("DELETE FROM saved_scans WHERE id = ?", (scan_id,))
                conn.commit()

        except Exception as e:
            self.logger.error(f"Error deleting saved scan {scan_id}: {str(e)}")
            raise

    def delete_folder_scan(self, folder_id: int) -> bool:
        """X√≥a folder scan v·ªõi retry logic"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                with self.get_connection() as conn:
                    # Begin transaction explicitly
                    conn.execute("BEGIN IMMEDIATE")
                    cursor = conn.execute("DELETE FROM folder_scans WHERE id = ?", (folder_id,))
                    conn.commit()
                    return cursor.rowcount > 0

            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and attempt < max_retries - 1:
                    import time
                    time.sleep(0.1 * (attempt + 1))
                    continue
                else:
                    self.logger.error(f"Error deleting folder scan {folder_id}: {str(e)}")
                    return False
            except Exception as e:
                self.logger.error(f"Error deleting folder scan {folder_id}: {str(e)}")
                return False
        
        return False

    def get_folder_scan_by_path(self, path: str) -> Optional[Dict[str, Any]]:
        """L·∫•y folder scan theo ƒë∆∞·ªùng d·∫´n"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("SELECT * FROM folder_scans WHERE path = ?", (path,))
                row = cursor.fetchone()
                return dict(row) if row else None

        except Exception as e:
            self.logger.error(f"Error getting folder scan by path {path}: {str(e)}")
            return None

    def create_folder_scan(self, folder_data: Dict[str, Any]) -> int:
        """T·∫°o folder scan m·ªõi"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    INSERT INTO folder_scans (
                        original_title, path, image_count, description, 
                        status, new_title, data_name, category_id, site_id
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    folder_data.get('original_title', ''),
                    folder_data.get('path', ''),
                    folder_data.get('image_count', 0),
                    folder_data.get('description', ''),
                    folder_data.get('status', 'pending'),
                    folder_data.get('new_title', ''),
                    folder_data.get('data_name', ''),
                    folder_data.get('category_id'),
                    folder_data.get('site_id')
                ))
                conn.commit()
                return cursor.lastrowid

        except Exception as e:
            self.logger.error(f"Error creating folder scan: {str(e)}")
            raise

    def search_folder_scans(self, search_term: str) -> List[Dict[str, Any]]:
        """T√¨m ki·∫øm folder scans theo t·ª´ kh√≥a"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT * FROM folder_scans 
                    WHERE original_title LIKE ? OR new_title LIKE ? OR path LIKE ?
                    ORDER BY id DESC
                """, (f"%{search_term}%", f"%{search_term}%", f"%{search_term}%"))

                columns = [description[0] for description in cursor.description]
                return [dict(zip(columns, row)) for row in cursor.fetchall()]

        except Exception as e:
            self.logger.error(f"Error searching folder scans: {str(e)}")
            return []

    def update_folder_ai_content(self, folder_id: int, new_title: str, description: str) -> bool:
        """C·∫≠p nh·∫≠t n·ªôi dung AI cho folder scan"""
        try:
            with self.get_connection() as conn:
                conn.execute("""
                    UPDATE folder_scans 
                    SET new_title = ?, description = ?, updated_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                """, (new_title, description, folder_id))
                conn.commit()
                return True

        except Exception as e:
            self.logger.error(f"Error updating folder AI content {folder_id}: {str(e)}")
            return False

    def get_folder_scans_by_status(self, status: str) -> List[Dict[str, Any]]:
        """L·∫•y folder scans theo tr·∫°ng th√°i"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT 
                        fs.*,
                        s.name as site_name,
                        c.name as category_name
                    FROM folder_scans fs
                    LEFT JOIN sites s ON fs.site_id = s.id
                    LEFT JOIN categories c ON fs.category_id = c.id
                    WHERE fs.status = ?
                    ORDER BY fs.created_at DESC
                """, (status,))

                columns = [description[0] for description in cursor.description]
                rows = cursor.fetchall()
                return [dict(zip(columns, row)) for row in rows]

        except Exception as e:
            self.logger.error(f"Error getting folder scans by status {status}: {str(e)}")
            return []

    def get_folder_scans_summary(self) -> Dict[str, Any]:
        """L·∫•y t·ªïng quan folder scans"""
        try:
            with self.get_connection() as conn:
                # T·ªïng s·ªë folder scans
                cursor = conn.execute("SELECT COUNT(*) as total FROM folder_scans")
                total = cursor.fetchone()['total']

                # Folder scans theo tr·∫°ng th√°i
                cursor = conn.execute("""
                    SELECT status, COUNT(*) as count 
                    FROM folder_scans 
                    GROUP BY status
                """)
                status_stats = {row['status']: row['count'] for row in cursor.fetchall()}

                # Folder scans theo site
                cursor = conn.execute("""
                    SELECT s.name, COUNT(fs.id) as count
                    FROM sites s
                    LEFT JOIN folder_scans fs ON s.id = fs.site_id
                    GROUP BY s.id, s.name
                """)
                site_stats = {row['name']: row['count'] for row in cursor.fetchall()}

                # T·ªïng s·ªë ·∫£nh
                cursor = conn.execute("SELECT SUM(image_count) as total_images FROM folder_scans")
                total_images = cursor.fetchone()['total_images'] or 0

                return {
                    'total_folders': total,
                    'total_images': total_images,
                    'by_status': status_stats,
                    'by_site': site_stats
                }

        except Exception as e:
            self.logger.error(f"Error getting folder scans summary: {str(e)}")
            return {}

    def cleanup_orphaned_folder_scans(self) -> int:
        """D·ªçn d·∫πp folder scans kh√¥ng c√≥ ƒë∆∞·ªùng d·∫´n h·ª£p l·ªá"""
        try:
            import os
            deleted_count = 0

            with self.get_connection() as conn:
                # L·∫•y t·∫•t c·∫£ folder scans
                cursor = conn.execute("SELECT id, path FROM folder_scans")
                folders = cursor.fetchall()

                for folder in folders:
                    if not os.path.exists(folder['path']):
                        conn.execute("DELETE FROM folder_scans WHERE id = ?", (folder['id'],))
                        deleted_count += 1
                        self.logger.info(f"Deleted orphaned folder scan {folder['id']}: {folder['path']}")

                conn.commit()
                self.logger.info(f"Cleaned up {deleted_count} orphaned folder scans")
                return deleted_count

        except Exception as e:
            self.logger.error(f"Error cleaning up orphaned folder scans: {str(e)}")
            return 0

    def get_duplicate_folder_scans(self) -> List[Dict[str, Any]]:
        """T√¨m c√°c folder scans tr√πng l·∫∑p theo ƒë∆∞·ªùng d·∫´n"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT path, COUNT(*) as count, GROUP_CONCAT(id) as ids
                    FROM folder_scans 
                    GROUP BY path 
                    HAVING COUNT(*) > 1
                    ORDER BY count DESC
                """)

                duplicates = []
                for row in cursor.fetchall():
                    duplicates.append({
                        'path': row['path'],
                        'count': row['count'],
                        'ids': [int(id_str) for id_str in row['ids'].split(',')]
                    })

                return duplicates

        except Exception as e:
            self.logger.error(f"Error finding duplicate folder scans: {str(e)}")
            return []

    def merge_duplicate_folder_scans(self, keep_id: int, merge_ids: List[int]) -> bool:
        """G·ªôp c√°c folder scans tr√πng l·∫∑p"""
        try:
            with self.get_connection() as conn:
                # L·∫•y th√¥ng tin folder gi·ªØ l·∫°i
                keeper = self.get_folder_scan_by_id(keep_id)
                if not keeper:
                    return False

                # G·ªôp th√¥ng tin t·ª´ c√°c folder b·ªã merge
                for merge_id in merge_ids:
                    merge_folder = self.get_folder_scan_by_id(merge_id)
                    if merge_folder:
                        # C·∫≠p nh·∫≠t keeper v·ªõi th√¥ng tin t·ªët nh·∫•t
                        update_data = {}

                        # ∆Øu ti√™n data_name c√≥ n·ªôi dung
                        if not keeper.get('data_name') and merge_folder.get('data_name'):
                            update_data['data_name'] = merge_folder['data_name']

                        # ∆Øu ti√™n description c√≥ n·ªôi dung
                        if not keeper.get('description') and merge_folder.get('description'):
                            update_data['description'] = merge_folder['description']

                        # ∆Øu ti√™n new_title c√≥ n·ªôi dung
                        if not keeper.get('new_title') and merge_folder.get('new_title'):
                            update_data['new_title'] = merge_folder['new_title']

                        # ∆Øu ti√™n site_id v√† category_id c√≥ gi√° tr·ªã
                        if not keeper.get('site_id') and merge_folder.get('site_id'):
                            update_data['site_id'] = merge_folder['site_id']

                        if not keeper.get('category_id') and merge_folder.get('category_id'):
                            update_data['category_id'] = merge_folder['category_id']

                        # C·∫≠p nh·∫≠t keeper n·∫øu c√≥ th√¥ng tin m·ªõi
                        if update_data:
                            self.update_folder_scan(keep_id, update_data)
                            keeper.update(update_data)

                # X√≥a c√°c folder b·ªã merge
                for merge_id in merge_ids:
                    conn.execute("DELETE FROM folder_scans WHERE id = ?", (merge_id,))

                conn.commit()
                self.logger.info(f"Merged {len(merge_ids)} folder scans into {keep_id}")
                return True

        except Exception as e:
            self.logger.error(f"Error merging duplicate folder scans: {str(e)}")
            return False

    def optimize_folder_scans_table(self):
        """T·ªëi ∆∞u b·∫£ng folder_scans"""
        try:
            with self.get_connection() as conn:
                # Vacuum ƒë·ªÉ t·ªëi ∆∞u database
                conn.execute("VACUUM")

                # Reindex ƒë·ªÉ t·ªëi ∆∞u indexes
                conn.execute("REINDEX")

                # Analyze ƒë·ªÉ c·∫≠p nh·∫≠t statistics
                conn.execute("ANALYZE")

                self.logger.info("Optimized folder_scans table")

        except Exception as e:
            self.logger.error(f"Error optimizing folder_scans table: {str(e)}")

    def export_folder_scans_to_json(self, file_path: str = None) -> str:
        """Export folder scans ra file JSON"""
        try:
            import json
            from datetime import datetime

            if not file_path:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_path = f"folder_scans_export_{timestamp}.json"

            folders = self.get_all_folder_scans()

            export_data = {
                'export_timestamp': datetime.now().isoformat(),
                'total_folders': len(folders),
                'folders': folders
            }

            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)

            self.logger.info(f"Exported {len(folders)} folder scans to {file_path}")
            return file_path

        except Exception as e:
            self.logger.error(f"Error exporting folder scans: {str(e)}")
            raise

    def save_pages_from_api(self, site_id: int, pages: list):
        """L∆∞u pages t·ª´ API v√†o database"""
        try:
            with self.get_connection() as conn:
                # X√≥a pages c≈© c·ªßa site n√†y tr∆∞·ªõc
                conn.execute("DELETE FROM pages WHERE site_id = ?", (site_id,))

                # L∆∞u t·ª´ng page
                for page in pages:
                    title = page.get('title', '')
                    if isinstance(title, dict):
                        title = title.get('rendered', '')

                    content = page.get('content', '')
                    if isinstance(content, dict):
                        content = content.get('rendered', '')

                    excerpt = page.get('excerpt', '')
                    if isinstance(excerpt, dict):
                        excerpt = excerpt.get('rendered', '')

                    conn.execute('''
                        INSERT OR REPLACE INTO pages 
                        (site_id, wp_page_id, title, slug, content, excerpt, status, 
                         parent_id, menu_order, featured_media, author, last_sync, updated_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                    ''', (
                        site_id,
                        page.get('id', 0),
                        title,
                        page.get('slug', ''),
                        content,
                        excerpt,
                        page.get('status', 'publish'),
                        page.get('parent', 0),
                        page.get('menu_order', 0),
                        page.get('featured_media', 0),
                        page.get('author', 0),
                        datetime.now().isoformat()
                    ))

                conn.commit()
                self.logger.info(f"Saved {len(pages)} pages for site {site_id}")

        except Exception as e:
            self.logger.error(f"Error saving pages: {str(e)}")
            raise

    def debug_category_mapping(self, site_id: int = None) -> Dict[str, Any]:
        """Debug category mapping ƒë·ªÉ ki·ªÉm tra t√¨nh tr·∫°ng ƒë·ªìng b·ªô"""
        try:
            with self.get_connection() as conn:
                if site_id:
                    # Debug cho site c·ª• th·ªÉ
                    cursor = conn.execute("""
                        SELECT c.*, s.name as site_name 
                        FROM categories c
                        LEFT JOIN sites s ON c.site_id = s.id
                        WHERE c.site_id = ?
                        ORDER BY c.name
                    """, (site_id,))
                else:
                    # Debug cho t·∫•t c·∫£ sites
                    cursor = conn.execute("""
                        SELECT c.*, s.name as site_name 
                        FROM categories c
                        LEFT JOIN sites s ON c.site_id = s.id
                        ORDER BY s.name, c.name
                    """)

                categories = [dict(row) for row in cursor.fetchall()]

                # T√≠nh to√°n th·ªëng k√™
                total_categories = len(categories)
                categories_with_wc_id = len([cat for cat in categories if cat.get('wc_category_id')])
                categories_without_wc_id = total_categories - categories_with_wc_id

                # Th·ªëng k√™ theo site
                site_stats = {}
                for cat in categories:
                    site_name = cat.get('site_name', 'Unknown')
                    if site_name not in site_stats:
                        site_stats[site_name] = {'total': 0, 'with_wc_id': 0}
                    site_stats[site_name]['total'] += 1
                    if cat.get('wc_category_id'):
                        site_stats[site_name]['with_wc_id'] += 1

                return {
                    'total_categories': total_categories,
                    'categories_with_wc_id': categories_with_wc_id,
                    'categories_without_wc_id': categories_without_wc_id,
                    'categories': categories,
                    'site_stats': site_stats
                }

        except Exception as e:
            self.logger.error(f"Error debugging category mapping: {str(e)}")
            return {
                'total_categories': 0,
                'categories_with_wc_id': 0,
                'categories_without_wc_id': 0,
                'categories': [],
                'site_stats': {}
            }

    def load_bulk_config(self, batch_id: int = None) -> Optional[str]:
        """Load bulk upload configuration from database"""
        try:
            # For now, return None since we don't have a config table yet
            # In the future, you could query a config table here
            self.logger.info("No saved bulk config found")
            return None

        except Exception as e:
            self.logger.error(f"Error loading bulk config: {str(e)}")
            return None

    def save_bulk_config(self, folders: List[Dict], config_json: str, batch_id: int = None) -> bool:
        """Save bulk upload configuration to database"""
        try:
            # For now, just log that config was saved
            # In the future, you could create a config table to persist this
            self.logger.info(f"Bulk config saved for {len(folders)} folders")
            return True

        except Exception as e:
            self.logger.error(f"Error saving bulk config: {str(e)}")
            return False